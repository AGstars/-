ResNet篇：

ResNet的基本结构是由多个残差模块组成的，每个残差模块包含了多个卷积层和批量标准化层，在每个残差模块中，
原始输入特征先经过一个捷径（Shortcut），然后再通过一个或多个卷积层进行非线性变换，将经过变换后的特征与捷径相加，得到残差（Residual），
再通过恒等映射（Identity Mapping）适应捷径和变换后的特征之间的尺寸差异。这样，特征在残差模块中可以直接进行传递，克服了梯度消失问题。

輸入→特徵（變成：輸入→ 輸入 + 殘差）
如果今天我們多一層，什麼都沒有學到。那殘差就是0
那多這一層，想想我們上面介紹過的，當殘差=0的時候，輸入→ 輸入，這一層就叫做恆等映射，
因此，多這一層如果沒學到新的特徵，也不會讓模型退化。實際上當然不會剛好等於0, 而是可以增加很多層，而每一層都可以學到一些新的更複雜的特徵。


- 可以通过增加或减少残差块的数量来调整模型的深度
- 可以通过修改卷积层的参数来改变模型的宽度
- 可以结合其他技术（如数据增强、正则化等）来进一步提升模型的性能

